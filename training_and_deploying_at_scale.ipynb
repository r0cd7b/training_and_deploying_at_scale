{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4579ff53-e818-43a4-b924-44adc9a9d862",
   "metadata": {},
   "source": [
    "**대규모 텐서플로 모델 훈련과 배포**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd38d987-20b3-4cc9-8574-73db1ddb1363",
   "metadata": {},
   "source": [
    "# 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22166b74-6cf6-428a-8e98-04b5655547b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-26 03:29:41.929061: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1756178982.070006      35 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1756178982.110370      35 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1756178982.425779      35 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756178982.425806      35 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756178982.425808      35 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756178982.425809      35 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-26 03:29:42.460236: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.config import list_physical_devices\n",
    "\n",
    "list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1be943-63b3-4d0c-8fde-1e5c405b05c2",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# 텐서플로 모델 서빙하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1309a9b1-51be-4201-acba-e8803420ea6b",
   "metadata": {},
   "source": [
    "## 텐서플로 서빙 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935d5b5c-5a56-4cd7-bd6f-3919a6685218",
   "metadata": {
    "id": "zKEy9mBwVFyD"
   },
   "source": [
    "가장 먼저 모델을 빌드하고 학습한 다음 SavedModel 포맷으로 내보낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2200fe-5cb1-4cc5-a972-bbcb699fe433",
   "metadata": {
    "id": "goSzUGwCVFyD"
   },
   "source": [
    "### SavedModel 내보내기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f750bdc2-70f0-4b2e-8218-2cbb3ee1e754",
   "metadata": {
    "id": "cRFHavXnVFyD"
   },
   "source": [
    "MNIST 데이터 세트를 로드하고, 스케일을 조정하고, 분할한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a01da7cc-bb70-49c1-bb5a-dc0d2efdd39d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1756178986.220986      35 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5555 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti, pci bus id: 0000:06:00.0, compute capability: 8.6\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1756178987.640871     139 service.cc:152] XLA service 0x7175d4005590 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1756178987.640916     139 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3070 Ti, Compute Capability 8.6\n",
      "2025-08-26 03:29:47.677816: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1756178987.742497     139 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-08-26 03:29:48.410858: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_38_0', 92 bytes spill stores, 96 bytes spill loads\n",
      "\n",
      "2025-08-26 03:29:48.655357: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_38', 532 bytes spill stores, 532 bytes spill loads\n",
      "\n",
      "2025-08-26 03:29:48.736011: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_38', 300 bytes spill stores, 300 bytes spill loads\n",
      "\n",
      "2025-08-26 03:29:48.886103: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_38', 1156 bytes spill stores, 1156 bytes spill loads\n",
      "\n",
      "2025-08-26 03:29:49.207503: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_175', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2025-08-26 03:29:49.240220: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_38', 5116 bytes spill stores, 5164 bytes spill loads\n",
      "\n",
      "2025-08-26 03:29:49.533498: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_38', 5256 bytes spill stores, 5240 bytes spill loads\n",
      "\n",
      "2025-08-26 03:29:49.534446: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_38', 392 bytes spill stores, 392 bytes spill loads\n",
      "\n",
      "2025-08-26 03:29:49.709396: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_175', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2025-08-26 03:29:49.741898: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_38', 76 bytes spill stores, 76 bytes spill loads\n",
      "\n",
      "2025-08-26 03:29:49.762379: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_175', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  80/1719\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2023 - loss: 2.1788"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1756178990.756577     139 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1706/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7186 - loss: 1.0548"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-26 03:29:54.612010: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_38', 72 bytes spill stores, 72 bytes spill loads\n",
      "\n",
      "2025-08-26 03:29:54.697321: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_38_0', 92 bytes spill stores, 92 bytes spill loads\n",
      "\n",
      "2025-08-26 03:29:54.737900: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_38', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2025-08-26 03:29:54.762234: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_38', 396 bytes spill stores, 396 bytes spill loads\n",
      "\n",
      "2025-08-26 03:29:54.946196: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_38', 536 bytes spill stores, 536 bytes spill loads\n",
      "\n",
      "2025-08-26 03:29:55.311045: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_175', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2025-08-26 03:29:55.532697: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_175', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2025-08-26 03:29:55.556534: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_38', 5248 bytes spill stores, 5240 bytes spill loads\n",
      "\n",
      "2025-08-26 03:29:55.572604: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_38', 284 bytes spill stores, 284 bytes spill loads\n",
      "\n",
      "2025-08-26 03:29:55.692857: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_38', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2025-08-26 03:29:55.793887: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_175', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2025-08-26 03:29:55.977365: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_38', 5108 bytes spill stores, 5160 bytes spill loads\n",
      "\n",
      "2025-08-26 03:29:56.106165: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_38', 1188 bytes spill stores, 1192 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7195 - loss: 1.0519"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-26 03:29:58.715729: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_34', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2025-08-26 03:29:58.749033: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_34', 296 bytes spill stores, 296 bytes spill loads\n",
      "\n",
      "2025-08-26 03:29:58.817648: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_34', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2025-08-26 03:29:58.953453: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_34', 792 bytes spill stores, 844 bytes spill loads\n",
      "\n",
      "2025-08-26 03:29:59.149940: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_34', 4632 bytes spill stores, 4676 bytes spill loads\n",
      "\n",
      "2025-08-26 03:29:59.224147: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_34', 4872 bytes spill stores, 4860 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8296 - loss: 0.6695 - val_accuracy: 0.9022 - val_loss: 0.3663\n",
      "INFO:tensorflow:Assets written to: my_mnist_model/0001/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_mnist_model/0001/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'my_mnist_model/0001'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 28, 28), dtype=tf.uint8, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  124754709362064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124754709361872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124754709357840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124754709362832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets.mnist import load_data\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras import Sequential, Input\n",
    "from tensorflow import uint8\n",
    "from tensorflow.keras.layers import Flatten, Rescaling, Dense\n",
    "from pathlib import Path\n",
    "\n",
    "mnist = load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = mnist\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "clear_session()\n",
    "model = Sequential([\n",
    "    Input((28, 28), dtype=uint8),\n",
    "    Flatten(),\n",
    "    Rescaling(1 / 255),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='SGD', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=1, validation_data=(X_valid, y_valid))  # epochs=10\n",
    "model_name = 'my_mnist_model'\n",
    "model_version = '0001'\n",
    "model_path = Path(model_name) / model_version\n",
    "model.export(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90a5f4d-5092-476c-8ed0-3786fd1e2a6b",
   "metadata": {
    "id": "uIK2q8hoVFyE"
   },
   "source": [
    "파일 트리를 살핀다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55fa7f31-2674-4886-9675-acc628b709b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my_mnist_model/0001',\n",
       " 'my_mnist_model/0001/assets',\n",
       " 'my_mnist_model/0001/fingerprint.pb',\n",
       " 'my_mnist_model/0001/saved_model.pb',\n",
       " 'my_mnist_model/0001/variables',\n",
       " 'my_mnist_model/0001/variables/variables.data-00000-of-00001',\n",
       " 'my_mnist_model/0001/variables/variables.index']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([str(path) for path in model_path.parent.glob('**/*')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f997f48b-af4c-4e15-9752-5cad0fdb4b18",
   "metadata": {
    "id": "7Cx61kc5VFyE"
   },
   "source": [
    "SavedModel을 검사한다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25fb662c-ea0a-46a5-aeff-6ca5f5509c6c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CQfjlLGzVFyE",
    "outputId": "bbdb9a4b-4c8b-4746-f20c-af746da30dc6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 03:30:00.143754: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1756179000.169031     444 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1756179000.173691     444 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1756179000.185992     444 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756179000.186040     444 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756179000.186047     444 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756179000.186050     444 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-26 03:30:00.190157: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "The given SavedModel contains the following tag-sets:\n",
      "'serve'\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir '{model_path}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35e4cefb-6632-476e-ba6b-43a056800717",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 03:30:03.227763: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1756179003.242215     461 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1756179003.246319     461 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1756179003.258156     461 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756179003.258205     461 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756179003.258211     461 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756179003.258214     461 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-26 03:30:03.261627: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "The given SavedModel MetaGraphDef contains SignatureDefs with the following keys:\n",
      "SignatureDef key: \"__saved_model_init_op\"\n",
      "SignatureDef key: \"serve\"\n",
      "SignatureDef key: \"serving_default\"\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir '{model_path}' --tag_set serve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12825c63-e383-4361-aba3-34aa148b4649",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 03:30:05.886667: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1756179005.900237     477 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1756179005.904271     477 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1756179005.915854     477 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756179005.915898     477 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756179005.915904     477 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756179005.915907     477 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-26 03:30:05.919293: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "The given SavedModel SignatureDef contains the following input(s):\n",
      "  inputs['keras_tensor'] tensor_info:\n",
      "      dtype: DT_UINT8\n",
      "      shape: (-1, 28, 28)\n",
      "      name: serving_default_keras_tensor:0\n",
      "The given SavedModel SignatureDef contains the following output(s):\n",
      "  outputs['output_0'] tensor_info:\n",
      "      dtype: DT_FLOAT\n",
      "      shape: (-1, 10)\n",
      "      name: StatefulPartitionedCall_1:0\n",
      "Method name is: tensorflow/serving/predict\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir '{model_path}' --tag_set serve --signature_def serving_default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0504ef0-5d1f-4831-8512-362ae21e54ec",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "더 자세한 내용을 보려면 다음 명령을 실행한다:\n",
    "```ipython\n",
    "!saved_model_cli show --dir '{model_path}' --all\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc51d78-b8b8-4f4b-aeca-16b54ab1b5e1",
   "metadata": {
    "id": "OvMBNdCDVFyF"
   },
   "source": [
    "### 텐서플로 서빙 설치 및 시작하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ae5e62-e4f1-4507-a58e-70a030912056",
   "metadata": {
    "id": "ueDMUZy7VFyG"
   },
   "source": [
    "도커를 사용해 TF 서빙을 설치하려면 먼저 [Docker](https://docs.docker.com/install/)가 설치되어 있는지 확인한 후 터미널에서 다음 명령을 실행한다.\n",
    "```bash\n",
    "docker pull tensorflow/serving:latest-gpu\n",
    "\n",
    "docker run -e MODEL_NAME=my_mnist_model --gpus all -it -p 8500:8500 -p 8501:8501 -v path\\to\\my_mnist_model:/models/my_mnist_model tensorflow/serving:latest-gpu\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0b417d-01e2-4ed3-97d5-a5c07c56b6e6",
   "metadata": {
    "id": "0AK-0xoYVFyG"
   },
   "source": [
    "### REST API로 TF 서빙에 쿼리하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74416a7e-a3bf-4549-a1ae-2b898d37b0dc",
   "metadata": {
    "id": "8xaftl-rVFyG"
   },
   "source": [
    "다음으로 TF 서빙에 REST 쿼리를 전송한다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72b136dc-6228-4ce9-9753-f105d56f5ebd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from json import dumps\n",
    "\n",
    "X_new = X_test[:3]  # 분류할 새로운 숫자 이미지가 3개 있다고 가정한다.\n",
    "request_json = dumps({'signature_name': 'serving_default', 'instances': X_new.tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b638da46-814b-4cd2-b672-22bef53eac8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"signature_name\": \"serving_default\", \"instances\": [[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0..., 0, 0]]]}'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request_json[:100] + '...' + request_json[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eeb304c-624a-4dba-aa13-78bc49f5537f",
   "metadata": {
    "id": "_xdNZs2rVFyG"
   },
   "source": [
    "이제 텐서플로 서빙의 REST API를 사용하여 예측한다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b284189-388f-4248-b657-b6989849e56b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from requests import post\n",
    "\n",
    "server_url = 'http://172.17.0.3:8501/v1/models/my_mnist_model:predict'\n",
    "response = post(server_url, request_json)\n",
    "response.raise_for_status()  # 오류 발생 시 예외 발생\n",
    "response = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c83742b4-2e82-495a-a630-f324923145d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.99, 0.  , 0.01],\n",
       "       [0.04, 0.  , 0.8 , 0.02, 0.  , 0.06, 0.06, 0.  , 0.02, 0.  ],\n",
       "       [0.  , 0.93, 0.02, 0.01, 0.  , 0.  , 0.  , 0.01, 0.01, 0.  ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import array\n",
    "\n",
    "y_proba = array(response['predictions'])\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173332e7-eec4-4113-9f2b-0a3ed1347b8c",
   "metadata": {
    "id": "eEiYgEi_VFyK"
   },
   "source": [
    "### gRPC API로 TF 서빙에 쿼리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b263222-947b-47db-b39c-395c1b9d3746",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow_serving.apis.predict_pb2 import PredictRequest\n",
    "from tensorflow import make_tensor_proto\n",
    "\n",
    "request = PredictRequest()\n",
    "request.model_spec.name = model_name\n",
    "request.model_spec.signature_name = 'serving_default'\n",
    "input_name = 'keras_tensor'\n",
    "request.inputs[input_name].CopyFrom(make_tensor_proto(X_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76c4f5bf-ee84-46fe-890f-d24e8139ff44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from grpc import insecure_channel\n",
    "from tensorflow_serving.apis.prediction_service_pb2_grpc import PredictionServiceStub\n",
    "\n",
    "channel = insecure_channel('172.17.0.3:8500')\n",
    "predict_service = PredictionServiceStub(channel)\n",
    "response = predict_service.Predict(request, timeout=10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa9b0e9-7982-4176-aadf-7c4334c6fe23",
   "metadata": {
    "id": "_a-7lekeVFyL"
   },
   "source": [
    "응답을 텐서로 변환한다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88e076ab-7ae0-45b1-8e98-a9c8fff4af45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow import make_ndarray\n",
    "\n",
    "output_name = 'output_0'\n",
    "outputs_proto = response.outputs[output_name]\n",
    "y_proba = make_ndarray(outputs_proto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81bdad44-b04b-4176-86ac-f867cc053dc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.99, 0.  , 0.01],\n",
       "       [0.04, 0.  , 0.8 , 0.02, 0.  , 0.06, 0.06, 0.  , 0.02, 0.  ],\n",
       "       [0.  , 0.93, 0.02, 0.01, 0.  , 0.  , 0.  , 0.01, 0.01, 0.  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22a5ccf-50bb-4eed-9b28-d676ac0d323b",
   "metadata": {
    "id": "MhgWRCnFVFyM"
   },
   "source": [
    "### 새 모델 버전 배포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c9e0f31-2bdd-447e-96aa-96ff87812019",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-26 03:30:11.733696: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_40', 944 bytes spill stores, 944 bytes spill loads\n",
      "\n",
      "2025-08-26 03:30:11.820326: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_40', 488 bytes spill stores, 488 bytes spill loads\n",
      "\n",
      "2025-08-26 03:30:11.915805: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_40', 940 bytes spill stores, 940 bytes spill loads\n",
      "\n",
      "2025-08-26 03:30:11.931325: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_40', 272 bytes spill stores, 272 bytes spill loads\n",
      "\n",
      "2025-08-26 03:30:12.081328: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_40', 1180 bytes spill stores, 1240 bytes spill loads\n",
      "\n",
      "2025-08-26 03:30:12.624054: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_196', 48 bytes spill stores, 48 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1701/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6600 - loss: 1.2093"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-26 03:30:18.080638: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_40', 272 bytes spill stores, 272 bytes spill loads\n",
      "\n",
      "2025-08-26 03:30:18.468659: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_40', 988 bytes spill stores, 988 bytes spill loads\n",
      "\n",
      "2025-08-26 03:30:18.478523: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_40', 484 bytes spill stores, 484 bytes spill loads\n",
      "\n",
      "2025-08-26 03:30:18.567163: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_40', 944 bytes spill stores, 944 bytes spill loads\n",
      "\n",
      "2025-08-26 03:30:18.696595: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_40', 956 bytes spill stores, 956 bytes spill loads\n",
      "\n",
      "2025-08-26 03:30:19.337906: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_196', 48 bytes spill stores, 48 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6616 - loss: 1.2042"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-26 03:30:22.173095: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_36', 348 bytes spill stores, 348 bytes spill loads\n",
      "\n",
      "2025-08-26 03:30:22.235963: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_36', 272 bytes spill stores, 272 bytes spill loads\n",
      "\n",
      "2025-08-26 03:30:22.423571: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_36', 816 bytes spill stores, 816 bytes spill loads\n",
      "\n",
      "2025-08-26 03:30:22.462491: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_36', 272 bytes spill stores, 272 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8082 - loss: 0.7184 - val_accuracy: 0.9030 - val_loss: 0.3458\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7176b57af950>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 새로운 MNIST 모델 버전 빌드 및 훈련\n",
    "model = Sequential([\n",
    "    Input((28, 28), dtype=uint8),\n",
    "    Flatten(),\n",
    "    Rescaling(1 / 255),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='SGD', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=1, validation_data=(X_valid, y_valid))  # epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d9fe824-534b-4ccf-8d3e-8809eaabfec2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_mnist_model/0002/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_mnist_model/0002/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'my_mnist_model/0002'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 28, 28), dtype=tf.uint8, name='keras_tensor_5')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  124754704634832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124754704632336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124754709358800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124754704633104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124754704632912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124754709359376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "model_version = '0002'\n",
    "model_path = Path(model_name) / model_version\n",
    "model.export(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f66c7c8-2a7e-44f7-b2b4-35466f690b1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my_mnist_model/0001',\n",
       " 'my_mnist_model/0001/assets',\n",
       " 'my_mnist_model/0001/fingerprint.pb',\n",
       " 'my_mnist_model/0001/saved_model.pb',\n",
       " 'my_mnist_model/0001/variables',\n",
       " 'my_mnist_model/0001/variables/variables.data-00000-of-00001',\n",
       " 'my_mnist_model/0001/variables/variables.index',\n",
       " 'my_mnist_model/0002',\n",
       " 'my_mnist_model/0002/assets',\n",
       " 'my_mnist_model/0002/fingerprint.pb',\n",
       " 'my_mnist_model/0002/saved_model.pb',\n",
       " 'my_mnist_model/0002/variables',\n",
       " 'my_mnist_model/0002/variables/variables.data-00000-of-00001',\n",
       " 'my_mnist_model/0002/variables/variables.index']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([str(path) for path in model_path.parent.glob('**/*')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3f2312-ea70-4614-b6f8-b0768ea9afe1",
   "metadata": {
    "id": "S31FFXYGVFyM"
   },
   "source": [
    "**경고**: 텐서플로 서빙이 새 모델을 로드하기까지 잠시 기다려야 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cdf01af0-3cc5-49f6-81c8-c5b9a67052c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "server_url = 'http://172.17.0.3:8501/v1/models/my_mnist_model:predict'\n",
    "response = post(server_url, request_json)\n",
    "response.raise_for_status()\n",
    "response = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e71bb055-45eb-44fa-940f-a818bf10a8a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['predictions'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9be5031-71a9-44a2-945f-f2f2a5369941",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.99, 0.  , 0.01],\n",
       "       [0.04, 0.  , 0.8 , 0.02, 0.  , 0.06, 0.06, 0.  , 0.02, 0.  ],\n",
       "       [0.  , 0.93, 0.02, 0.01, 0.  , 0.  , 0.  , 0.01, 0.01, 0.  ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba = array(response['predictions'])\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dc9ce0-b366-4bd5-b62a-fa5aa8e8c234",
   "metadata": {
    "id": "8aWy9ECgVFyQ"
   },
   "source": [
    "# 모바일 또는 임베디드 디바이스에 모델 배포하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b1f58ef-9a06-4d10-9ed0-22983a58b254",
   "metadata": {
    "id": "N-O3Sc0DVFyQ",
    "outputId": "faad2986-11a2-4b74-cb56-da7700ad00f0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1756179026.407785      35 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1756179026.407837      35 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2025-08-26 03:30:26.411063: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: my_mnist_model/0002\n",
      "2025-08-26 03:30:26.414109: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-08-26 03:30:26.414121: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: my_mnist_model/0002\n",
      "I0000 00:00:1756179026.418217      35 mlir_graph_optimization_pass.cc:425] MLIR V1 optimization pass is not enabled\n",
      "2025-08-26 03:30:26.418814: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-08-26 03:30:26.442368: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: my_mnist_model/0002\n",
      "2025-08-26 03:30:26.447803: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 36745 microseconds.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import lite\n",
    "\n",
    "converter = lite.TFLiteConverter.from_saved_model(str(model_path))\n",
    "tflite_model = converter.convert()\n",
    "with open('my_converted_savedmodel.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "072d43a1-342b-4db7-a710-36f3bc0cd299",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 케라스 모델을 변환한다.\n",
    "converter = lite.TFLiteConverter.from_keras_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "004f03ef-f673-41d7-89df-abffe1f4d4db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "converter.optimizations = [lite.Optimize.DEFAULT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b948b09d-8fc7-42a3-9df6-e8b2f291e7d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpp3xus6sh/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpp3xus6sh/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpp3xus6sh'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 28, 28), dtype=tf.uint8, name='keras_tensor_5')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  124754704634832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124754704632336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124754709358800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124754704633104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124754704632912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124754709359376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1756179026.722468      35 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1756179026.722510      35 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2025-08-26 03:30:26.722660: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpp3xus6sh\n",
      "2025-08-26 03:30:26.723063: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-08-26 03:30:26.723069: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpp3xus6sh\n",
      "2025-08-26 03:30:26.725578: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-08-26 03:30:26.740786: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpp3xus6sh\n",
      "2025-08-26 03:30:26.745809: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 23151 microseconds.\n"
     ]
    }
   ],
   "source": [
    "tflite_model = converter.convert()\n",
    "with open('my_converted_keras_model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589267a9-3fd1-444a-9c03-5e8d3a58b2ef",
   "metadata": {
    "id": "Y4VfgmwVVFyR"
   },
   "source": [
    "# GPU를 사용하여 계산 속도 향상하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb9c72f-e270-42c6-b4eb-bb196d91f165",
   "metadata": {
    "id": "pWEx4a31VFyR"
   },
   "source": [
    "텐서플로우가 GPU를 볼 수 있는지 확인한다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23058587-b68e-4cb1-9e07-16ec4e185f39",
   "metadata": {
    "id": "xVJNYyroVFyR",
    "outputId": "e5daa069-3b41-49cd-dee2-efbbf0a42d50",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "physical_gpus = list_physical_devices('GPU')\n",
    "physical_gpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd909e6c-65b4-4896-9d0c-a2d124590b9a",
   "metadata": {
    "id": "h20yT_y6VFyR"
   },
   "source": [
    "텐서플로 스크립트에서 GPU \\#0과 \\#1(PCI 순서 기준)만 사용하려면 스크립트를 시작하기 전에 환경 변수 `CUDA_DEVICE_ORDER=PCI_BUS_ID`와 `CUDA_VISIBLE_DEVICES=0,1`을 설정한다. 또는 스크립트 자체에서 텐서플로를 사용하기 전에 지정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e6a78b-5fed-4c9b-a32d-93acbf3e5da5",
   "metadata": {
    "id": "_zNPhsERVFyS"
   },
   "source": [
    "## GPU RAM 관리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ae7b96-e875-42bc-8da4-f5f6c357fb01",
   "metadata": {
    "id": "HItL_tIeVFyS"
   },
   "source": [
    "RAM 용량을 GPU당 2GB로 제한하려면:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "06882804-b29a-4ce6-bf5d-1e75a442fef0",
   "metadata": {
    "id": "ByepjvQaVFyS",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for gpu in physical_gpus:\n",
    "#     config.set_logical_device_configuration(gpu, [config.LogicalDeviceConfiguration(2048)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fda924e-d313-4f60-8d8f-42174b568bc6",
   "metadata": {
    "id": "cKiDo2ciVFyS"
   },
   "source": [
    "점진적으로 텐서플로가 메모리를 점유하도록 하려면(프로세스가 종료될 때만 메모리를 해제한다):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c84b001-01c5-4d0e-b2a9-f12d07e08979",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.config.experimental import set_memory_growth\n",
    "\n",
    "# for gpu in physical_gpus:\n",
    "#     set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a755ab8-e0a3-45b8-9001-be95c738457d",
   "metadata": {
    "id": "Az0uZINuVFyS"
   },
   "source": [
    "이와 동일하게, 텐서플로를 사용하기 전에 `TF_FORCE_GPU_ALLOW_GROWTH` 환경 변수를 `true`로 설정할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4fdcf0-9321-4198-951e-e7f761acc159",
   "metadata": {
    "id": "qU0QW2dEVFyS"
   },
   "source": [
    "물리적 GPU를 두 개의 논리적 GPU로 분할한다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b63962f-0a86-4130-a716-bdaac5b81efd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.config import LogicalDeviceConfiguration\n",
    "\n",
    "# set_logical_device_configuration(physical_gpus[0], [LogicalDeviceConfiguration(2048), LogicalDeviceConfiguration(2048)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "00e3d58b-9c34-45ee-8975-1d9d0d300560",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogicalDevice(name='/device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.config import list_logical_devices\n",
    "\n",
    "logical_gpus = list_logical_devices('GPU')\n",
    "logical_gpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53776656-f9bc-4d01-84ba-03cede9399a6",
   "metadata": {
    "id": "dHhdR7oKVFyT"
   },
   "source": [
    "## 디바이스에 연산 및 변수 배치하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca76fce-eb77-4f07-a54b-bb498a18e55c",
   "metadata": {
    "id": "IW9RswfNVFyT"
   },
   "source": [
    "모든 변수 및 연산 배치를 기록하려면(이 작업은 텐서플로를 임포팅한 직후에 실행해야 한다):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "573e0e44-ca0c-4db9-9d7b-5dc14e445cc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow import get_logger\n",
    "from tensorflow.debugging import set_log_device_placement\n",
    "\n",
    "get_logger().setLevel(\"DEBUG\")  # 디폴트 로그 수준은 INFO다.\n",
    "set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "07cd9706-cd2c-430e-882c-1c14de283fcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/job:localhost/replica:0/task:0/device:GPU:0'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import Variable\n",
    "\n",
    "a = Variable([1., 2., 3.])  # float32 변수는 GPU로 이동한다.\n",
    "a.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d7310da-6336-4efa-a8b7-50c909d5605f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/job:localhost/replica:0/task:0/device:CPU:0'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = Variable([1, 2, 3])  # int32 변수는 CPU로 이동한다.\n",
    "b.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584c1090-bc98-4782-9260-6496f5f86d76",
   "metadata": {
    "id": "CVMtpGUTVFyU"
   },
   "source": [
    "`tf.device()` 컨텍스트를 사용하여 원하는 장치에 변수 및 연산을 수동으로 배치할 수 있다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f03f77de-6201-4d8b-84e3-3015eba30cea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/job:localhost/replica:0/task:0/device:CPU:0'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import device\n",
    "\n",
    "with device('/CPU:0'):\n",
    "    c = Variable([1., 2., 3.])\n",
    "c.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27da4192-62b2-423c-88ae-75c08cca1e6f",
   "metadata": {
    "id": "3kFjB8ByVFyU"
   },
   "source": [
    "존재하지 않거나 커널이 없는 장치를 지정하면 텐서플로는 자동으로 기본 장치를 사용한다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f0b8d3ad-bfc8-41e7-b149-b59a3a720b83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/job:localhost/replica:0/task:0/device:GPU:0'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with device('/GPU:1234'):\n",
    "    d = Variable([1., 2., 3.])\n",
    "d.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db79217-3d2a-4ff8-be96-567f5113a3c7",
   "metadata": {
    "id": "gikk9azaVFyU"
   },
   "source": [
    "텐서플로에서 존재하지 않는 장치를 사용하려고 할 때 기본 장치로 되돌아가지 않고 예외를 발생시키려면:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9a3bb84e-1066-4e17-b397-b2233270fbed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not satisfy device specification '/job:localhost/replica:0/task:0/device:GPU:1000'. enable_soft_placement=0. Supported device types [GPU, CPU]. All available devices [/job:localhost/replica:0/task:0/device:GPU:0, /job:localhost/replica:0/task:0/device:CPU:0].\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.config import set_soft_device_placement\n",
    "from tensorflow.errors import InvalidArgumentError\n",
    "\n",
    "set_soft_device_placement(False)\n",
    "try:\n",
    "    with device('/GPU:1000'):\n",
    "        d = Variable([1., 2., 3.])\n",
    "except InvalidArgumentError as ex:\n",
    "    print(ex)\n",
    "set_soft_device_placement(True)  # 소프트 배치로 돌아가기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73129f1-375c-4117-bc25-dc11872495ed",
   "metadata": {
    "id": "axTbpgvtVFyU"
   },
   "source": [
    "## 여러 디바이스에서 병렬 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c619d41-870f-4ad8-9526-a4b104809598",
   "metadata": {
    "id": "4Ar1AawCVFyU"
   },
   "source": [
    "inter-op 또는 intra-op 스레드 수를 설정하려는 경우(CPU 포화를 방지하거나 완벽하게 재현 가능한 테스트 케이스를 실행하기 위해 텐서플로를 단일 스레드로 만들고자 하는 경우 유용하다):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b7ab432a-033f-48b7-9262-2227aa95089f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.config.threading import set_inter_op_parallelism_threads\n",
    "\n",
    "# set_inter_op_parallelism_threads(10)\n",
    "# set_intra_op_parallelism_threads(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e7df63-b4aa-4118-90c7-cb0e99b07119",
   "metadata": {
    "id": "uMH0X27cVFyV",
    "tags": []
   },
   "source": [
    "# 여러 디바이스에서 모델 훈련하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e419ecc1-8d23-4401-bf8f-bbe14f504294",
   "metadata": {
    "id": "GbS0MW8VVFyV"
   },
   "source": [
    "## 분산 전략 API를 사용한 대규모 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "df29123d-769f-40fd-a38a-d6af76408e89",
   "metadata": {
    "id": "tlwMePdtVFyV",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Reshape, Conv2D, MaxPool2D, Dropout\n",
    "\n",
    "\n",
    "# 케라스를 사용하여 MNIST용 CNN 모델을 생성한다.\n",
    "def create_model():\n",
    "    return Sequential([\n",
    "        Input((28, 28), dtype=uint8),\n",
    "        Reshape([28, 28, 1]),\n",
    "        Rescaling(1 / 255),\n",
    "        Conv2D(64, 7, padding='same', activation='relu'),\n",
    "        MaxPool2D(2),\n",
    "        Conv2D(128, 3, padding='same', activation='relu'),\n",
    "        Conv2D(128, 3, padding='same', activation='relu'),\n",
    "        MaxPool2D(2),\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(.5),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7e31c2c4-b7cf-4c29-84da-abd9aef028f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m547/550\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3687 - loss: 1.8798INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-26 03:30:34.084492: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "2025-08-26 03:30:34.084599: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m550/550\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.5760 - loss: 1.3121 - val_accuracy: 0.9094 - val_loss: 0.3285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-26 03:30:34.584449: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7176dc0c7910>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import distribute\n",
    "\n",
    "strategy = distribute.MirroredStrategy()\n",
    "with strategy.scope():\n",
    "    model = create_model()  # 일반적인 케라스 모델을 생성한다.\n",
    "    model.compile('SGD', 'sparse_categorical_crossentropy', metrics=['accuracy'])  # 모델을 컴파일한다.\n",
    "batch_size = 100  # 복제본 수로 나누어지는 것이 바람직하다.\n",
    "model.fit(X_train, y_train, batch_size, 1, validation_data=(X_valid, y_valid))  # epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "78ada289-e28d-4b71-ac0b-94d536ef3f27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.distribute.mirrored_strategy.MirroredStrategy at 0x7176a3936e50>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.distribute_strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "764fbfe1-ed21-4103-abc4-0e4fbb33ad63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.99, 0.  , 0.  , 0.  , 0.01, 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.96, 0.01, 0.  , 0.  , 0.  , 0.01, 0.  , 0.01, 0.  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_new).round(2)  # 배치가 모든 복제본에 분할된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "79cf3188-eb53-49b3-8ffc-9c942e2aded7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy at 0x7176b7d1a110>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 모델을 저장해도 분산 전략이 보존되지 않는다.\n",
    "model.save('my_mirrored_model.keras')\n",
    "model = load_model('my_mirrored_model.keras')\n",
    "model.distribute_strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7e0d09e3-36f4-43ce-8afc-a5c56b498183",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = load_model('my_mirrored_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "88b3348c-737c-43eb-9dd6-a7acaeedeb44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.distribute.mirrored_strategy.MirroredStrategy at 0x7176a3936e50>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.distribute_strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada3952d-5e04-4ea9-b0d6-1d10f232c02f",
   "metadata": {
    "id": "WN3CledCVFyW"
   },
   "source": [
    "사용할 GPU 리스트를 지정하려는 경우:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5a31f483-6659-4e4e-9e81-2a3fe077a5dd",
   "metadata": {
    "id": "cA4CHPHkVFyW",
    "outputId": "05fd42b0-f2ff-472d-a5f9-2793f365d7b7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    }
   ],
   "source": [
    "strategy = distribute.MirroredStrategy(['/GPU:0', '/GPU:1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e53cfc8-0d65-42fc-8d50-7c3afa9b5423",
   "metadata": {
    "id": "akC4byspVFyW"
   },
   "source": [
    "기본 all-reduce 알고리즘을 변경하려는 경우:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0a5970d1-f6cc-40e0-ab68-d9014597820e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    }
   ],
   "source": [
    "strategy = distribute.MirroredStrategy(cross_device_ops=distribute.HierarchicalCopyAllReduce())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdeee82-ca53-4d2b-afc8-820b8df3ea32",
   "metadata": {
    "id": "Pq3ZG2YsVFyX"
   },
   "source": [
    "`CentralStorageStrategy`을 사용하려는 경우:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "101c9f50-a91d-4a4a-92d9-3425ba65c787",
   "metadata": {
    "id": "U-JeJwYMVFyX",
    "outputId": "593f93fa-d500-43e4-c9de-90cd70e9a67c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:ParameterServerStrategy (CentralStorageStrategy if you are using a single machine) with compute_devices = ['/job:localhost/replica:0/task:0/device:GPU:0'], variable_device = '/job:localhost/replica:0/task:0/device:GPU:0'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:ParameterServerStrategy (CentralStorageStrategy if you are using a single machine) with compute_devices = ['/job:localhost/replica:0/task:0/device:GPU:0'], variable_device = '/job:localhost/replica:0/task:0/device:GPU:0'\n"
     ]
    }
   ],
   "source": [
    "strategy = distribute.experimental.CentralStorageStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "041ef3ea-e065-480c-92aa-bd7fb8264c47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distribute.cluster_resolver.TPUClusterResolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "872623ef-3376-4887-8626-18f1b3f829c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sys import modules\n",
    "from os import environ\n",
    "from tensorflow.config import experimental_connect_to_cluster\n",
    "from tensorflow.tpu.experimental import initialize_tpu_system\n",
    "\n",
    "# Google Colab에서 TPU로 훈련하기:\n",
    "if 'google.colab' in modules and 'COLAB_TPU_ADDR' in environ:\n",
    "    tpu_address = 'grpc://' + environ['COLAB_TPU_ADDR']\n",
    "else:\n",
    "    tpu_address = ''\n",
    "# resolver = distribute.cluster_resolver.TPUClusterResolver(tpu_address)\n",
    "# experimental_connect_to_cluster(resolver)\n",
    "# initialize_tpu_system(resolver)\n",
    "# strategy = distribute.TPUStrategy(resolver)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3907f9e-2604-4b44-9747-e5a6b1966a6b",
   "metadata": {
    "id": "zRyn37DGVFyX"
   },
   "source": [
    "## 텐서플로 클러스터에서 모델 훈련하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5418e8-5599-4d51-8301-711d2a5bf3c0",
   "metadata": {
    "id": "C6wg7-g7VFyX"
   },
   "source": [
    "텐서플로 클러스터는 일반적으로 서로 다른 컴퓨터에서 병렬로 실행되며 신경망 훈련이나 실행과 같은 작업을 완료하기 위해 서로 대화하는 텐서플로 프로세스의 그룹이다. 클러스터의 각 TF 프로세스를 \"태스크\"(또는 \"TF 서버\")라고 한다. IP 주소, 포트, 타입(역할 또는 작업이라고도 함)이 있다. 타입은 `\"worker\"`, `\"chief\"`, `\"ps\"`(파라미터 서버) 또는 `\"evaluator\"`가 될 수 있다:\n",
    "* **워커**는 일반적으로 하나 이상의 GPU가 있는 컴퓨터에서 계산을 수행한다.\n",
    "* **치프**는 계산도 수행하지만, 텐서보드 로그 작성이나 체크포인트 저장과 같은 추가 작업도 처리한다. 클러스터에는 하나의 치프가 있다. 정의되지 않은 경우 워커 #0이 치프가 된다.\n",
    "* **파라미터 서버**(ps)는 변수 값만 추적하며, 일반적으로 CPU 전용 머신에 있다.\n",
    "* **이밸류에이터**는 당연히 평가를 담당한다. 일반적으로 클러스터에는 하나의 이밸류에이터가 있다.\n",
    "\n",
    "같은 유형의 태스크 집합을 흔히 \"작업(job)\"이라고 한다. 예를 들어 \"워커\" 작업은 모든 워커 태스크의 집합이다.\n",
    "\n",
    "텐서플로 클러스터를 시작하려면 먼저 클러스터를 정의해야 한다. 즉, 모든 작업(IP 주소, TCP 포트 및 타입)을 지정해야 한다. 예를 들어, 다음 클러스터 사양은 3개의 태스크(워커 2개, 파라미터 서버 1개)가 있는 클러스터를 정의한다. 작업당 하나의 키가 있는 사전이며, 값은 태스크 주소 목록이다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "da22a4d2-8644-451a-abaa-cb69b5354e76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cluster_spec = {\n",
    "    'worker': ['machine-a.example.com:2222', 'machine-b.example.com:2222'], 'ps': ['machine-a.example.com:2221']\n",
    "    # [/job:worker/task:0, /job:worker/task:1], [/job:ps/task:0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a0872f53-4d77-4419-8e80-b5475d93ac72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "environ['TF_CONFIG'] = dumps({'cluster': cluster_spec, 'task': {'type': 'worker', 'index': 0}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c1b5b0-aabd-47ca-ab9a-7c6217ea54f1",
   "metadata": {
    "id": "S6iYPbcFVFyY"
   },
   "source": [
    "일부 플랫폼(예: 구글 버텍스 AI)에서는 이 환경 변수를 자동으로 설정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37ec60d-bde0-4279-aacc-ec191ce422b4",
   "metadata": {
    "id": "_m0-G1zhVFyY"
   },
   "source": [
    "텐서플로의 `TFConfigClusterResolver` 클래스는 이 환경 변수에서 클러스터 구성을 읽는다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5a5904c4-f0a2-4a69-b3c4-f6ff06bdf13f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClusterSpec({'ps': ['machine-a.example.com:2221'], 'worker': ['machine-a.example.com:2222', 'machine-b.example.com:2222']})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resolver = distribute.cluster_resolver.TFConfigClusterResolver()\n",
    "resolver.cluster_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b5c13e70-7f2d-4a0a-b32d-7d333611b434",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'worker'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resolver.task_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e872ddc1-99d6-4fa6-9714-58f4c79c6baf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resolver.task_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03533c67-84e6-4f3a-9453-95a966bb1ec5",
   "metadata": {
    "id": "UchJJ_e-VFyY"
   },
   "source": [
    "이제 로컬 컴퓨터에서 두 개의 워커 태스크를 가진 간단한 클러스터를 실행한다. `MultiWorkerMirroredStrategy`을 사용하여 두 태스크로 모델을 훈련한다.\n",
    "\n",
    "첫 번째 단계는 훈련 코드를 작성하는 것이다. 이 코드를 사용해 두 워커에서 각각 고유한 프로세스로 실행하므로 별도의 파이썬 파일인 `my_mnist_multiworker_task.py`에 작성한다. 코드는 비교적 간단하지만 주의해야 할 몇 가지 중요한 사항이 있다:\n",
    "* 텐서플로로 다른 작업을 수행하기 전에 `MultiWorkerMirroredStrategy`을 생성한다.\n",
    "* 워커 중 하나만 텐서보드 로깅을 처리한다. 앞서 언급했듯이 이 작업자를 *치프*라고 한다. 명시적으로 정의되지 않은 경우 워커 #0이 치프다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1f50ce8d-4601-4eeb-b91e-a72e9ecf3a03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting my_mnist_multiworker_task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile my_mnist_multiworker_task.py\n",
    "from tensorflow import distribute\n",
    "from tf_keras.datasets.mnist import load_data\n",
    "from tf_keras import Sequential, Input\n",
    "from tensorflow import uint8\n",
    "from tf_keras.layers import Reshape, Rescaling, Conv2D, MaxPool2D, Flatten, Dense, Dropout\n",
    "from tempfile import mkdtemp\n",
    "from tensorflow.io.gfile import rmtree\n",
    "\n",
    "strategy = distribute.MultiWorkerMirroredStrategy()  # 시작 부분에!\n",
    "resolver = distribute.cluster_resolver.TFConfigClusterResolver()\n",
    "print(f'Starting task {resolver.task_type} #{resolver.task_id}')\n",
    "# MNIST 데이터셋 로드 및 분할\n",
    "mnist = load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = mnist\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "with strategy.scope():\n",
    "    model = Sequential([\n",
    "        Input((28, 28), dtype=uint8),\n",
    "        Reshape((28, 28, 1)),\n",
    "        Rescaling(1 / 255),\n",
    "        Conv2D(64, 7, padding='same', activation='relu'),\n",
    "        MaxPool2D(2),\n",
    "        Conv2D(128, 3, padding='same', activation='relu'),\n",
    "        Conv2D(128, 3, padding='same', activation='relu'),\n",
    "        MaxPool2D(2),\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(.5),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile('SGD', 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=1, validation_data=(X_valid, y_valid))  # epochs=10\n",
    "if resolver.task_id == 0:  # 치프는 모델을 올바른 위치에 저장한다.\n",
    "    model.export('my_mnist_multiworker_model')\n",
    "else:\n",
    "    tmpdir = mkdtemp()  # 다른 워커는 임시 디렉터리에 저장한다.\n",
    "    model.export(tmpdir)\n",
    "    rmtree(tmpdir)  # 마지막에 이 디렉터리를 삭제할 수 있다!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef83b73-7c9b-4cc3-98c3-37dfe93d2c7a",
   "metadata": {
    "id": "KyPpRrL2VFyZ"
   },
   "source": [
    "실제 애플리케이션에서는 일반적으로 머신당 하나의 워커가 있지만, 이 예제에서는 동일한 머신에서 두 워커를 모두 실행하고 있으므로 두 워커 모두 사용 가능한 모든 GPU RAM(이 머신에 GPU가 있는 경우)을 사용하려고 시도하므로 메모리 부족(OOM) 오류가 발생할 수 있다. 이를 방지하기 위해 `CUDA_VISIBLE_DEVICES` 환경 변수를 사용하여 각 워커에 다른 GPU를 할당한다. 또는 `CUDA_VISIBLE_DEVICES`를 빈 문자열로 설정하여 간단히 GPU 지원을 비활성화한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7967388e-bb7c-4b43-8a9a-5f5ca85df75b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash --bg\n",
    "export CUDA_VISIBLE_DEVICES=''\n",
    "export TF_CONFIG='{\"cluster\": {\"worker\": [\"127.0.0.1:9901\", \"127.0.0.1:9902\"]}, \"task\": {\"type\": \"worker\", \"index\": 0}}'\n",
    "python my_mnist_multiworker_task.py &> my_worker_0.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3373a749-4014-4c70-8e38-46418da464db",
   "metadata": {
    "id": "gOd7b7jkVFyZ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash --bg\n",
    "export CUDA_VISIBLE_DEVICES=''\n",
    "export TF_CONFIG='{\"cluster\": {\"worker\": [\"127.0.0.1:9901\", \"127.0.0.1:9902\"]}, \"task\": {\"type\": \"worker\", \"index\": 1}}'\n",
    "python my_mnist_multiworker_task.py &> my_worker_1.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd4ac97-cb11-4a67-b908-faf68561d354",
   "metadata": {
    "id": "mwguA2F-VFyZ"
   },
   "source": [
    "**참고**: `AutoShardPolicy`에 대한 경고가 표시되면 무시해도 무방하다. 자세한 내용은 [TF 이슈 #42146](https://github.com/tensorflow/tensorflow/issues/42146)을 참고한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7907ea36-b7f0-4368-874a-55045532ea7c",
   "metadata": {
    "id": "2oTt8nDlVFyZ"
   },
   "source": [
    "끝났다! 이제 텐서플로 클러스터가 실행 중이지만 별도의 프로세스에서 실행 중이므로 이 노트북에서는 볼 수 없다(하지만 진행 상황은 `my_worker_*.log`에서 확인할 수 있다)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f68226c0-408b-4739-9727-118601a62beb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# strategy = distribute.MultiWorkerMirroredStrategy(communication_options=distribute.experimental.CommunicationOptions(\n",
    "#     implementation=distribute.experimental.CommunicationImplementation.NCCL\n",
    "# ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbeef41-21ec-4326-9d42-9ce0381cdb26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
