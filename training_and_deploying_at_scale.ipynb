{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8be2d33-68c3-4d1e-b4c6-aee3bb1679c0",
   "metadata": {},
   "source": [
    "**대규모 텐서플로 모델 훈련과 배포**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4c7388-3dc1-45c8-90cb-aebe5198e126",
   "metadata": {},
   "source": [
    "# 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfbd4812-1c54-4e92-94ce-8d26ff1c6cf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82720141-6f93-43d3-84a9-97f63a9dcb78",
   "metadata": {},
   "source": [
    "이 노트북에서는 하나 이상의 GPU에서 모델을 실행하거나 훈련하는 방법을 수행하므로 적어도 하나 이상의 GPU가 있는지 확인하거나 그렇지 않으면 경고를 발행한다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f3ba37e-a0dd-4deb-b703-c2dc66c0150d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-25 09:34:16.284679: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-25 09:34:16.535924: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-25 09:34:16.536173: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print('GPU가 감지되지 않았습니다. 신경망은 GPU가 없으면 매우 느릴 수 있습니다.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a302920-7cf5-4a22-b4a2-9f844f630944",
   "metadata": {},
   "source": [
    "# 텐서플로 모델 서빙하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1936bf3-dd02-4f0f-bd0a-797c5a7034f8",
   "metadata": {},
   "source": [
    "# 대규모 텐서플로 모델 훈련과 배포"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1c2ff9-c5b7-4792-b6b0-3da7383a8c70",
   "metadata": {},
   "source": [
    "먼저 TF 서빙을 사용하여 모델을 배포한 다음 Google Vertex AI에 배포한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e23cf9b-894e-493e-88c2-1dd4a535903c",
   "metadata": {},
   "source": [
    "## 텐서플로 서빙 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd1dc51-9a83-493c-9a50-2ae3a7467c5d",
   "metadata": {},
   "source": [
    "가장 먼저 해야 할 일은 모델을 빌드하고 학습한 다음 SavedModel 포맷으로 내보내는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd4e5fc-df01-4b84-8694-b0cd1f2cfa12",
   "metadata": {},
   "source": [
    "### SavedModel 내보내기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a7fa29-25d2-4b4a-9c70-9fc5f214ebb7",
   "metadata": {},
   "source": [
    "MNIST 데이터 세트를 로드하고, 스케일을 조정하고, 분할한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87cd2a54-4de6-41fb-86e7-c9e45bb49544",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-25 09:43:07.873967: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-25 09:43:07.874316: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-25 09:43:07.874520: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-25 09:43:08.034058: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-25 09:43:08.034314: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-25 09:43:08.034332: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-02-25 09:43:08.034553: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-25 09:43:08.034608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5557 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti, pci bus id: 0000:06:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-25 09:43:09.309192: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-02-25 09:43:09.502211: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f27d083a110 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-02-25 09:43:09.502251: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3070 Ti, Compute Capability 8.6\n",
      "2024-02-25 09:43:09.654228: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8903\n",
      "2024-02-25 09:43:09.909859: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-02-25 09:43:10.095065: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.6816 - accuracy: 0.8304 - val_loss: 0.3677 - val_accuracy: 0.8998\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3493 - accuracy: 0.9031 - val_loss: 0.2992 - val_accuracy: 0.9160\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3001 - accuracy: 0.9161 - val_loss: 0.2643 - val_accuracy: 0.9288\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2691 - accuracy: 0.9239 - val_loss: 0.2417 - val_accuracy: 0.9312\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2455 - accuracy: 0.9313 - val_loss: 0.2228 - val_accuracy: 0.9382\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2268 - accuracy: 0.9364 - val_loss: 0.2075 - val_accuracy: 0.9404\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2110 - accuracy: 0.9401 - val_loss: 0.1942 - val_accuracy: 0.9470\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1973 - accuracy: 0.9447 - val_loss: 0.1829 - val_accuracy: 0.9498\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1854 - accuracy: 0.9482 - val_loss: 0.1737 - val_accuracy: 0.9512\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1749 - accuracy: 0.9514 - val_loss: 0.1648 - val_accuracy: 0.9556\n",
      "INFO:tensorflow:Assets written to: my_mnist_model/0001/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_mnist_model/0001/assets\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# MNIST 데이터 세트 로드 및 분할\n",
    "mnist = tf.keras.datasets.mnist.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = mnist\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "# MNIST 모델 구축 및 훈련(이미지 전처리도 처리)\n",
    "tf.keras.backend.clear_session()\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Flatten(input_shape=[28, 28], dtype=tf.uint8),\n",
    "        tf.keras.layers.Rescaling(1 / 255),\n",
    "        tf.keras.layers.Dense(100, 'relu'),\n",
    "        tf.keras.layers.Dense(10, 'softmax')\n",
    "    ]\n",
    ")\n",
    "model.compile(tf.keras.optimizers.experimental.SGD(1e-2), 'sparse_categorical_crossentropy', ['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\n",
    "model_name = 'my_mnist_model'\n",
    "model_version = '0001'\n",
    "model_path = Path(model_name) / model_version\n",
    "model.save(model_path, save_format='tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37449e67-e805-4b8f-a716-9300105a156d",
   "metadata": {},
   "source": [
    "파일 트리를 살핀다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d40f2428-2699-49a6-882c-56aed7899d18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my_mnist_model/0001',\n",
       " 'my_mnist_model/0001/assets',\n",
       " 'my_mnist_model/0001/fingerprint.pb',\n",
       " 'my_mnist_model/0001/keras_metadata.pb',\n",
       " 'my_mnist_model/0001/saved_model.pb',\n",
       " 'my_mnist_model/0001/variables',\n",
       " 'my_mnist_model/0001/variables/variables.data-00000-of-00001',\n",
       " 'my_mnist_model/0001/variables/variables.index',\n",
       " 'my_mnist_model/0002',\n",
       " 'my_mnist_model/0002/fingerprint.pb',\n",
       " 'my_mnist_model/0002/saved_model.pb',\n",
       " 'my_mnist_model/0002/variables',\n",
       " 'my_mnist_model/0002/variables/variables.data-00000-of-00001',\n",
       " 'my_mnist_model/0002/variables/variables.index']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([str(path) for path in model_path.parent.glob('**/*')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4862448f-eb63-48ed-a79e-9112c07e0ad7",
   "metadata": {},
   "source": [
    "SavedModel을 검사한다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f328c7bf-f979-4ee0-a1d1-c46a07a7eaf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-25 09:55:18.828532: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-25 09:55:20.010246: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-25 09:55:20.025038: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-25 09:55:20.025256: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "The given SavedModel contains the following tag-sets:\n",
      "'serve'\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir '{model_path}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "229f033f-eece-4931-811f-c23e8eaac838",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-25 09:55:52.834180: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-25 09:55:54.026782: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-25 09:55:54.040408: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-25 09:55:54.040778: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "The given SavedModel MetaGraphDef contains SignatureDefs with the following keys:\n",
      "SignatureDef key: \"__saved_model_init_op\"\n",
      "SignatureDef key: \"serving_default\"\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir '{model_path}' --tag_set serve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1d911da-a777-47a8-af9a-636b20cf12fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-25 09:56:21.276452: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-25 09:56:22.441738: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-25 09:56:22.456355: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-25 09:56:22.456633: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "The given SavedModel SignatureDef contains the following input(s):\n",
      "  inputs['flatten_input'] tensor_info:\n",
      "      dtype: DT_UINT8\n",
      "      shape: (-1, 28, 28)\n",
      "      name: serving_default_flatten_input:0\n",
      "The given SavedModel SignatureDef contains the following output(s):\n",
      "  outputs['dense_1'] tensor_info:\n",
      "      dtype: DT_FLOAT\n",
      "      shape: (-1, 10)\n",
      "      name: StatefulPartitionedCall:0\n",
      "Method name is: tensorflow/serving/predict\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir '{model_path}' --tag_set serve --signature_def serving_default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc89f5dc-cd74-4cb9-93c0-6094df452f93",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "823a66c6-282c-4386-b0a6-7babc339d300",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_mnist_model/\n",
      "    0001/\n",
      "        fingerprint.pb\n",
      "        saved_model.pb\n",
      "        assets/\n",
      "        variables/\n",
      "            variables.data-00000-of-00001\n",
      "            variables.index\n"
     ]
    }
   ],
   "source": [
    "for root, _, files in os.walk(model_name):\n",
    "    indent = '    ' * root.count(os.sep)\n",
    "    print(f'{indent}{os.path.basename(root)}/')\n",
    "    for filename in files:\n",
    "        print(f'{indent}    {filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9eeaa47-f869-4976-a8d4-1755a2b65efb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-21 08:15:39.794518: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-21 08:15:41.048459: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-21 08:15:41.073743: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-21 08:15:41.074078: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "The given SavedModel contains the following tag-sets:\n",
      "'serve'\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir {model_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ffe2698-12f5-48e1-a072-93d1ef899f94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-21 08:15:42.674465: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-21 08:15:43.816225: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-21 08:15:43.832320: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-21 08:15:43.832573: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "The given SavedModel MetaGraphDef contains SignatureDefs with the following keys:\n",
      "SignatureDef key: \"__saved_model_init_op\"\n",
      "SignatureDef key: \"serving_default\"\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir {model_path} --tag_set serve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "993b397d-74c6-4347-b0d9-6ac9f5b9fa66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-21 08:15:44.604485: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-21 08:15:45.993620: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-21 08:15:46.015223: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-21 08:15:46.015645: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "The given SavedModel SignatureDef contains the following input(s):\n",
      "  inputs['flatten_input'] tensor_info:\n",
      "      dtype: DT_FLOAT\n",
      "      shape: (-1, 28, 28, 1)\n",
      "      name: serving_default_flatten_input:0\n",
      "The given SavedModel SignatureDef contains the following output(s):\n",
      "  outputs['dense_1'] tensor_info:\n",
      "      dtype: DT_FLOAT\n",
      "      shape: (-1, 10)\n",
      "      name: StatefulPartitionedCall:0\n",
      "Method name is: tensorflow/serving/predict\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir '{model_path}' --tag_set serve --signature_def serving_default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94ec01b-0373-447f-ae0b-4198d853b11b",
   "metadata": {},
   "source": [
    "더 자세한 내용을 보려면 다음 명령을 실행한다:\n",
    "\n",
    "```ipython\n",
    "!saved_model_cli show --dir '{model_path}' --all\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1d6afd-0847-4ad8-850b-f399f7aac59f",
   "metadata": {},
   "source": [
    "### 텐서플로 서빙 설치 및 시작하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c719e36-8526-4395-ae3a-f5e274b6d76a",
   "metadata": {},
   "source": [
    "이 노트북을 실행하는 경우, 텐서플로 서버를 설치해야 한다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2949ac03-4f29-4344-aca5-9656ec367cc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  2943  100  2943    0     0  32340      0 --:--:-- --:--:-- --:--:-- 32340\n",
      "OK\n",
      "Hit:1 https://storage.googleapis.com/tensorflow-serving-apt stable InRelease\n",
      "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
      "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
      "Hit:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
      "Hit:6 http://archive.ubuntu.com/ubuntu focal InRelease\n",
      "Hit:7 http://security.ubuntu.com/ubuntu focal-security InRelease\n",
      "Hit:8 http://archive.ubuntu.com/ubuntu focal-updates InRelease\n",
      "Hit:9 http://archive.ubuntu.com/ubuntu focal-backports InRelease\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "All packages are up to date.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "tensorflow-model-server is already the newest version (2.14.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "url = 'https://storage.googleapis.com/tensorflow-serving-apt'\n",
    "src = 'stable tensorflow-model-server tensorflow-model-server-universal'\n",
    "!echo 'deb {url} {src}' > /etc/apt/sources.list.d/tensorflow-serving.list\n",
    "!curl '{url}/tensorflow-serving.release.pub.gpg' | apt-key add -\n",
    "!apt update -q && apt-get install -y tensorflow-model-server\n",
    "%pip install -q -U tensorflow-serving-api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b6bd04-4626-4b85-81c9-de79f2802570",
   "metadata": {},
   "source": [
    "`tensorflow_model_server`가 설치된 경우 다음 2개의 셀을 실행하여 서버를 시작한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db5c6183-16f0-4b1d-9c36-bacebf7b5f8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"MODEL_DIR\"] = str(model_path.parent.absolute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "27f766c1-a510-438f-8259-7d1ca9272d73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash --bg\n",
    "tensorflow_model_server --port=8500 --rest_api_port=8501 --model_name=my_mnist_model --model_base_path=\"${MODEL_DIR}\" &> my_server.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d1a590-031f-45e8-8cc0-659dcb408ea5",
   "metadata": {},
   "source": [
    "도커를 사용해 TF 서빙을 설치하려면 먼저 [Docker](https://docs.docker.com/install/)가 설치되어 있는지 확인한 후 터미널에서 다음 명령을 실행한다. `path/to/my_mnist_model`을 `my_mnist_model` 디렉토리의 적절한 절대 경로로 대체해야 하지만, 컨테이너 경로 `/models/my_mnist_model`은 수정하지 않는다.\n",
    "```bash\n",
    "docker pull tensorflow/serving  # 최신 TF 서빙 이미지 다운로드\n",
    "docker run -it --rm -v \"/path/to/my_mnist_model:/models/my_mnist_model\" -p 8500:8500 -p 8501:8501 -e MODEL_NAME=my_mnist_model tensorflow/serving\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c07c6f-68dd-468e-b182-26185d28854f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9c20f9-3ef7-4d84-96d9-6bfebf50405e",
   "metadata": {},
   "source": [
    "**REST API로 TF 서빙에 쿼리하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6f1796a-c923-48e9-9321-ad10f2a57dcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "input_data_json = json.dumps({\"signature_name\": \"serving_default\", \"instances\": X_new.tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb340a9a-76f5-46eb-9687-7fcecc22f0fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\'{\"signature_name\": \"serving_default\", \"instances\": [[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.32941177487373...'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repr(input_data_json)[:1500] + '...'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193e141e-90f2-4c5b-82d9-f1139257ce14",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "이제 텐서플로 서빙의 REST API를 사용해 예측을 만든다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a11a0ee4-ff6b-45b9-9567-5dc439c7a811",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "SERVER_URL = 'http://172.17.0.3:8501/v1/models/my_mnist_model:predict'\n",
    "response = requests.post(SERVER_URL, input_data_json)\n",
    "response.raise_for_status()  # 에러가 생길 경우 예외를 발생한다.\n",
    "response = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09d78c76-d1de-46c2-acc1-51a7fa9cc652",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['predictions'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9327a37a-af89-4877-8cdf-6a6d63a00860",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.99, 0.  , 0.01],\n",
       "       [0.05, 0.  , 0.74, 0.03, 0.  , 0.08, 0.08, 0.  , 0.02, 0.  ],\n",
       "       [0.  , 0.94, 0.02, 0.01, 0.  , 0.  , 0.01, 0.01, 0.01, 0.  ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba = np.array(response['predictions'])\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9161b6f4-43a8-4e74-8d2e-db0be2b9c839",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "**gRPC API로 TF 서빙에 쿼리하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad38e828-88af-49cc-ada7-54f566e576e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow_serving.apis.predict_pb2 import PredictRequest\n",
    "\n",
    "request = PredictRequest()\n",
    "request.model_spec.name = model_name\n",
    "request.model_spec.signature_name = 'serving_default'\n",
    "input_name = model.input_names[0]\n",
    "request.inputs[input_name].CopyFrom(tf.make_tensor_proto(X_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6cec6512-d76a-4aa5-b6bd-688569ccbb82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import grpc\n",
    "from tensorflow_serving.apis import prediction_service_pb2_grpc\n",
    "\n",
    "channel = grpc.insecure_channel('172.17.0.3:8500')\n",
    "predict_service = prediction_service_pb2_grpc.PredictionServiceStub(channel)\n",
    "response = predict_service.Predict(request, timeout=10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60ffbc37-b9af-4454-9d65-1318ee97f2e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_spec {\n",
       "  name: \"my_mnist_model\"\n",
       "  version {\n",
       "    value: 1\n",
       "  }\n",
       "  signature_name: \"serving_default\"\n",
       "}\n",
       "outputs {\n",
       "  key: \"dense_1\"\n",
       "  value {\n",
       "    dtype: DT_FLOAT\n",
       "    tensor_shape {\n",
       "      dim {\n",
       "        size: 3\n",
       "      }\n",
       "      dim {\n",
       "        size: 10\n",
       "      }\n",
       "    }\n",
       "    float_val: 0.000402979786\n",
       "    float_val: 5.88208832e-06\n",
       "    float_val: 0.000366911176\n",
       "    float_val: 0.00135380519\n",
       "    float_val: 0.000246009586\n",
       "    float_val: 0.00012352725\n",
       "    float_val: 6.24434233e-06\n",
       "    float_val: 0.986865819\n",
       "    float_val: 0.000193533\n",
       "    float_val: 0.010435285\n",
       "    float_val: 0.0472884588\n",
       "    float_val: 0.00201013405\n",
       "    float_val: 0.741884887\n",
       "    float_val: 0.0263824854\n",
       "    float_val: 4.35053189e-05\n",
       "    float_val: 0.0835964605\n",
       "    float_val: 0.077808\n",
       "    float_val: 1.3808849e-05\n",
       "    float_val: 0.0208080988\n",
       "    float_val: 0.000164117519\n",
       "    float_val: 0.000934983371\n",
       "    float_val: 0.935363352\n",
       "    float_val: 0.0228319\n",
       "    float_val: 0.0100065954\n",
       "    float_val: 0.00207439577\n",
       "    float_val: 0.00379154854\n",
       "    float_val: 0.00599071104\n",
       "    float_val: 0.00524047157\n",
       "    float_val: 0.0101381978\n",
       "    float_val: 0.00362782134\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238dbfea-338f-4d22-b8b4-4d13ab14806d",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "응답을 텐서로 변환한다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6828776-9594-4e39-b6b7-770b43e2ef71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.99, 0.  , 0.01],\n",
       "       [0.05, 0.  , 0.74, 0.03, 0.  , 0.08, 0.08, 0.  , 0.02, 0.  ],\n",
       "       [0.  , 0.94, 0.02, 0.01, 0.  , 0.  , 0.01, 0.01, 0.01, 0.  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_name = model.output_names[0]\n",
    "outputs_proto = response.outputs[output_name]\n",
    "y_proba = tf.make_ndarray(outputs_proto)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e371f65-9add-41ea-9c62-0c8d2c35404b",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "클라이언트가 텐서플로 라이브러리를 사용하지 않는다면 넘파이 배열로 변환한다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65f17131-684d-44bf-b8e9-9ce7817c8655",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.99, 0.  , 0.01],\n",
       "       [0.05, 0.  , 0.74, 0.03, 0.  , 0.08, 0.08, 0.  , 0.02, 0.  ],\n",
       "       [0.  , 0.94, 0.02, 0.01, 0.  , 0.  , 0.01, 0.01, 0.01, 0.  ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_name = model.output_names[0]\n",
    "outputs_proto = response.outputs[output_name]\n",
    "shape = [dim.size for dim in outputs_proto.tensor_shape.dim]\n",
    "y_proba = np.array(outputs_proto.float_val).reshape(shape)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b04d18-68d6-40f7-8c0c-6207651babdf",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "**새로운 버전의 모델 배포하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3706a0fb-e877-451b-9d4c-d9a97c91df6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.7323 - accuracy: 0.7955 - val_loss: 0.3438 - val_accuracy: 0.9082\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3241 - accuracy: 0.9070 - val_loss: 0.2710 - val_accuracy: 0.9276\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2712 - accuracy: 0.9218 - val_loss: 0.2377 - val_accuracy: 0.9352\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2388 - accuracy: 0.9307 - val_loss: 0.2107 - val_accuracy: 0.9418\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2138 - accuracy: 0.9381 - val_loss: 0.1985 - val_accuracy: 0.9454\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.1950 - accuracy: 0.9436 - val_loss: 0.1762 - val_accuracy: 0.9544\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.1777 - accuracy: 0.9480 - val_loss: 0.1661 - val_accuracy: 0.9560\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.1643 - accuracy: 0.9518 - val_loss: 0.1605 - val_accuracy: 0.9566\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.1517 - accuracy: 0.9561 - val_loss: 0.1442 - val_accuracy: 0.9608\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.1412 - accuracy: 0.9586 - val_loss: 0.1358 - val_accuracy: 0.9640\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Flatten(input_shape=[28, 28, 1]),\n",
    "        keras.layers.Dense(50, 'relu'),\n",
    "        keras.layers.Dense(50, 'relu'),\n",
    "        keras.layers.Dense(10, 'softmax')\n",
    "    ]\n",
    ")\n",
    "model.compile(keras.optimizers.experimental.SGD(), 'sparse_categorical_crossentropy', ['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea3454d9-1696-4c94-97b5-935f0ca2952f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my_mnist_model/0002'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_version = '0002'\n",
    "model_name = 'my_mnist_model'\n",
    "model_path = os.path.join(model_name, model_version)\n",
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a400cd14-3ccc-4688-a527-60f750ebe1e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_mnist_model/0002/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_mnist_model/0002/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9cca4efc-65f9-47a3-a08f-64d7e772aead",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_mnist_model/\n",
      "    0001/\n",
      "        fingerprint.pb\n",
      "        saved_model.pb\n",
      "        assets/\n",
      "        variables/\n",
      "            variables.data-00000-of-00001\n",
      "            variables.index\n",
      "    0002/\n",
      "        fingerprint.pb\n",
      "        saved_model.pb\n",
      "        assets/\n",
      "        variables/\n",
      "            variables.data-00000-of-00001\n",
      "            variables.index\n"
     ]
    }
   ],
   "source": [
    "for root, _, files in os.walk(model_name):\n",
    "    indent = '    ' * root.count(os.sep)\n",
    "    print(f'{indent}{os.path.basename(root)}/')\n",
    "    for filename in files:\n",
    "        print(f'{indent}    {filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5ab993-1505-4f0f-86fd-21261c39b4ed",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "**경고**: 새로운 모델이 텐서플로 서빙에 로드되기 전까지 잠시 기다려야 할 수 있다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "195ce5b3-35b0-4cb6-85c5-2094e837dde0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SERVER_URL = 'http://172.17.0.3:8501/v1/models/my_mnist_model:predict'\n",
    "response = requests.post(SERVER_URL, input_data_json)\n",
    "response.raise_for_status()\n",
    "response = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9e2472cc-c628-49ac-be95-61fa7db01f71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['predictions'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c2410fa2-2977-474d-b89e-30e0e777c00f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.99, 0.  , 0.01],\n",
       "       [0.05, 0.  , 0.74, 0.03, 0.  , 0.08, 0.08, 0.  , 0.02, 0.  ],\n",
       "       [0.  , 0.94, 0.02, 0.01, 0.  , 0.  , 0.01, 0.01, 0.01, 0.  ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba = np.array(response['predictions'])\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48c69f4-2e82-4751-93f0-88cd82cbdde5",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### 예측 서비스 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b273d5-c49a-4a51-a0cb-beb8dd71027a",
   "metadata": {},
   "source": [
    "**구글 클라우드 클라이언트 라이브러리**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48813479-fc1b-49eb-8b55-15415298890b",
   "metadata": {},
   "source": [
    "구글 클라우드 AI 플랫폼에 모델을 배포하고, 서비스 계정의 개인키를 다운로드하여 프로젝트 디렉토리에 저장한다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2bbf270a-323e-455e-b8e4-1081c824b567",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"mineral-trainer-394903-4289c79f86b1.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "947a749c-a9d0-4ef0-a430-bae2a68e4808",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from google.protobuf import json_format\n",
    "from google.protobuf.struct_pb2 import Value\n",
    "\n",
    "\n",
    "def predict_custom_trained_model_sample(\n",
    "        project, endpoint_id, instances, location='us-central1', api_endpoint='us-central1-aiplatform.googleapis.com'\n",
    "):\n",
    "    client_options = {'api_endpoint': api_endpoint}\n",
    "    client = aiplatform.gapic.PredictionServiceClient(client_options=client_options)\n",
    "    instances = instances if isinstance(instances, list) else [instances]\n",
    "    instances = [json_format.ParseDict(instance_dict, Value()) for instance_dict in instances]\n",
    "    parameters_dict = {}\n",
    "    parameters = json_format.ParseDict(parameters_dict, Value())\n",
    "    endpoint = client.endpoint_path(project=project, location=location, endpoint=endpoint_id)\n",
    "    response = client.predict(endpoint=endpoint, instances=instances, parameters=parameters)\n",
    "    predictions = response.predictions\n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2426b16e-471a-4f19-bb35-c85856f8eb79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.99, 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  ]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_probas = predict_custom_trained_model_sample(\n",
    "    '759555954445',\n",
    "    '8228789002740695040',\n",
    "    X_new.tolist(),\n",
    "    'asia-northeast3',\n",
    "    'asia-northeast3-aiplatform.googleapis.com'\n",
    ")\n",
    "np.round(Y_probas, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92886901-954d-41c5-aa95-0f0034fa1b53",
   "metadata": {},
   "source": [
    "# 모바일 또는 임베디드 디바이스에 모델 배포하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "542692a1-a796-4947-a4f5-64c06dac36ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lite\n\u001b[0;32m----> 3\u001b[0m converter \u001b[38;5;241m=\u001b[39m lite\u001b[38;5;241m.\u001b[39mTFLiteConverter\u001b[38;5;241m.\u001b[39mfrom_saved_model(\u001b[38;5;28mstr\u001b[39m(\u001b[43mmodel_path\u001b[49m))\n\u001b[1;32m      4\u001b[0m tflite_model \u001b[38;5;241m=\u001b[39m converter\u001b[38;5;241m.\u001b[39mconvert()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmy_converted_savedmodel.tflite\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_path' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow import lite\n",
    "\n",
    "converter = lite.TFLiteConverter.from_saved_model(str(model_path))\n",
    "tflite_model = converter.convert()\n",
    "with open('my_converted_savedmodel.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c434903-f959-44bf-a7d4-c5cf27ee62ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
